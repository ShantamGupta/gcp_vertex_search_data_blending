{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f2112dc-6f63-414e-bf79-eb262752a248",
   "metadata": {},
   "source": [
    "### Create a Search App with Mixed Datastores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9251ab7-4a41-4a7e-b675-3822308c50f8",
   "metadata": {},
   "source": [
    "1. Follow the steps listed here to create a Search App https://cloud.google.com/generative-ai-app-builder/docs/create-engine-es \n",
    "2. Create the relevant datastores(GCS, BQ, Website) https://cloud.google.com/generative-ai-app-builder/docs/create-data-store-es\n",
    "3. Link the Datstores to the Search App https://cloud.google.com/generative-ai-app-builder/docs/create-data-store-es#multi-data-stores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab58f9f-ceba-4eea-8ac0-5fbd36eac78d",
   "metadata": {},
   "source": [
    "### Install the Relevant packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739fb52f-7ca7-4fdc-993b-c8b88fdec713",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install google-cloud-discoveryengine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de73be91-7a1c-4df5-bf08-3a447b158a57",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Import the Relevant packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "052f7cf3-f34f-402c-a08b-978130e18cf8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import the relevant library\n",
    "#ignore the warnings\n",
    "\n",
    "from typing import List\n",
    "from google.api_core.client_options import ClientOptions\n",
    "from google.cloud import discoveryengine as discoveryengine\n",
    "import vertexai\n",
    "from vertexai.preview.generative_models import GenerativeModel, Part\n",
    "import vertexai.preview.generative_models as generative_models\n",
    "import requests\n",
    "import subprocess  # To obtain the access token\n",
    "import re\n",
    "import json\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "379ae518-563b-4bf0-a1fc-b2b121414cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID=\"PROJECT_ID\"\n",
    "SEARCH_APP_LOCATION=\"global or us\"\n",
    "SEARCH_ENGINE_ID=\"VERTEX_SEARCH_ENGINE_ID\"\n",
    "LOCATION_GEMINI_MODEl=\"northamerica-northeast1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96ed5da-e479-4270-8169-ba534a2a2550",
   "metadata": {},
   "source": [
    "### Send a Request to Vertex Search App with Data Blending(Mixed Datastore) \n",
    "#### https://cloud.google.com/generative-ai-app-builder/docs/create-data-store-es#multi-data-stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12ac92a-ac23-4f36-b2c8-8e5fbd40b6ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Obtain the access token\n",
    "access_token = subprocess.check_output(['gcloud', 'auth', 'print-access-token']).decode('utf-8').strip()\n",
    "\n",
    "# Construct the API endpoint URL\n",
    "url = \"https://discoveryengine.googleapis.com/v1beta/projects/\" + PROJECT_ID + \"/locations/\" + SEARCH_APP_LOCATION + \"/collections/default_collection/engines/\" + SEARCH_ENGINE_ID + \"/servingConfigs/default_search:search\"\n",
    "\n",
    "# Headers for the request\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {access_token}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "# Data payload for the POST request\n",
    "data = {\n",
    "    \"servingConfig\": \"projects/\" + PROJECT_ID + \"/locations/\" + SEARCH_APP_LOCATION + \"/collections/default_collection/engines/\" + SEARCH_ENGINE_ID + \"/servingConfigs/default_search\", \n",
    "    \"query\": \"How many 10-ks in the datastore \",  # <- insert your search prompt/query \n",
    "    \"pageSize\": \"10\" \n",
    "}\n",
    "\n",
    "# Send the POST request\n",
    "response = requests.post(url, headers=headers, json=data) \n",
    "\n",
    "# Check for successful response\n",
    "if response.status_code == 200:\n",
    "    output = response.text\n",
    "    print(output)\n",
    "else:\n",
    "    print(f\"Request failed with status code: {response.status_code}\")\n",
    "    #uncommen below to see the results\n",
    "    #print(response.text) \n",
    "\n",
    "# Store response is in a variable called 'response_data'\n",
    "response_data = response.json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d8058308-f25d-497a-91dd-db0337cf390a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Uncomment to extract snippets from search results\n",
    "\n",
    "# for idx, result in enumerate(response_data['results']):\n",
    "#     document = result['document']\n",
    "#     if 'derivedStructData' in document:\n",
    "#         print(f\"\\n--- Snippets from Document {idx+1} ---\")\n",
    "#         for snippet_item in document['derivedStructData'].get('snippets', []):\n",
    "#             print(snippet_item['snippet'])\n",
    "            \n",
    "\n",
    "\n",
    "#Uncomment to clean up regex from snippets\n",
    "\n",
    "# snippets_list = []\n",
    "\n",
    "# for idx, result in enumerate(response_data['results']):\n",
    "#     # ... (your existing code)\n",
    "#         for snippet_item in document['derivedStructData'].get('snippets', []):\n",
    "#             snippets_list.append(snippet_item['snippet'])\n",
    "# for item in snippets_list:\n",
    "#     clean_text = re.sub('<[^>]*>', '', item)  \n",
    "#     print(clean_text)\n",
    "#     print(\"\\n\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fc8d60-be4a-4831-8330-4c0470f85c3c",
   "metadata": {},
   "source": [
    "### Feed the Search result snippets to Gemini Pro model and formuate a summary/response based on your original prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "42950f35-7b64-4c7d-9ce3-3bbeb8224c9e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4 10-ks in the datastore."
     ]
    }
   ],
   "source": [
    "def generate():\n",
    "  vertexai.init(project=PROJECT_ID, location=LOCATION_GEMINI_MODEl)\n",
    "  model = GenerativeModel(\"gemini-1.0-pro-001\") #specify the gemini model version\n",
    "  responses = model.generate_content(\n",
    "     str(response_data) + \" organize the json results based on the question :\" +data['query'],\n",
    "    generation_config={\n",
    "        \"max_output_tokens\": 2048,\n",
    "        \"temperature\": 0.9,\n",
    "        \"top_p\": 1\n",
    "    },\n",
    "    safety_settings={\n",
    "          generative_models.HarmCategory.HARM_CATEGORY_HATE_SPEECH: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
    "          generative_models.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
    "          generative_models.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
    "          generative_models.HarmCategory.HARM_CATEGORY_HARASSMENT: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
    "    },\n",
    "    stream=True,\n",
    "  )\n",
    "  \n",
    "  for response in responses:\n",
    "    print(response.text, end=\"\")\n",
    "\n",
    "\n",
    "generate()"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-15.m118",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-gpu.2-15:m118"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
